{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10-playground.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "HrQ5Ciw3sxfC",
        "i2l3OCtQsR5j",
        "nA1EFebsZ9MG",
        "-b3p96M2aBcW"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/y0umu/pytorch-cifar10-playground/blob/master/cifar10_playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89XkIk57YkvX",
        "colab_type": "text"
      },
      "source": [
        "# Preparations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7h-b-3tYkfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install -U -q tensorboardX\n",
        "# tensorboardX might not be neccessary in the future as pytorch started\n",
        "# to add experimental torch.utils.tensorboard support in 1.1.0. \n",
        "# The syntax is very similiar to that of tensorboardX\n",
        "# see https://pytorch.org/docs/stable/tensorboard.html for more details"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF7lAYsLL4qo",
        "colab_type": "code",
        "outputId": "706284e0-21d6-4a97-96f9-80b59e0af2d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# hopefully we can try TF 2.0 to use tensorboard directly in notebook\n",
        "!pip install -q tf-nightly-2.0-preview\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrQ5Ciw3sxfC",
        "colab_type": "text"
      },
      "source": [
        "## Pydrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7RlABXKtTTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dMHrK37X9nj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if the upload has to fail I will do that manually\n",
        "from pathlib import Path\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# !mkdir authentication\n",
        "\n",
        "gauth = GoogleAuth()\n",
        "gauth.LoadCredentialsFile(\"mycreds.txt\")\n",
        "if gauth.credentials is None:\n",
        "    # Authenticate if they're not there\n",
        "    # self.gauth.LocalWebserverAuth()\n",
        "    print(\"no creds saved\")\n",
        "    auth.authenticate_user()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "elif gauth.access_token_expired:\n",
        "    # Refresh them if expired\n",
        "    print(\"token expired\")\n",
        "    gauth.Refresh()\n",
        "else:\n",
        "    # Initialize the saved creds\n",
        "    print(\"Initialize the saved creds\")\n",
        "    gauth.Authorize()\n",
        "# Save the current credentials to a file\n",
        "gauth.SaveCredentialsFile(\"mycreds.txt\") \n",
        "\n",
        "\n",
        "############################################\n",
        "# the_drive = GoogleDrive(gauth)\n",
        "# ckpt_name = \"ResCsNet-colab-5_2_1-r0.10_checkpoint.pth\"\n",
        "\n",
        "\n",
        "# id_file = Path('_id')\n",
        "# if id_file.exists():\n",
        "#     print(\"_id exsits\")\n",
        "#     fileid = id_file.read_text()\n",
        "#     _gfile_ckpt = the_drive.CreateFile({'id': fileid})\n",
        "#     _gfile_ckpt.SetContentFile(ckpt_name)\n",
        "#     _gfile_ckpt.Upload()\n",
        "# else:\n",
        "#     print(\"_id not exsits\")\n",
        "#     _gfile_ckpt = the_drive.CreateFile()      \n",
        "#     _gfile_ckpt.SetContentFile(ckpt_name)\n",
        "#     _gfile_ckpt.Upload()\n",
        "#     id_file.write_text(_gfile_ckpt['id']) \n",
        "print(\"Done\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2l3OCtQsR5j",
        "colab_type": "text"
      },
      "source": [
        "## Old style hacks\n",
        "These hacks are intended for backup and view tensorboard thru a third-party remote host. Hopefully they will not have to be used in the future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA1EFebsZ9MG",
        "colab_type": "text"
      },
      "source": [
        "### http.server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHadh223ZhQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw(\"python3 -m http.server 8000 --bind 127.0.0.1 &\")\n",
        "!ps -ef | grep http"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-b3p96M2aBcW",
        "colab_type": "text"
      },
      "source": [
        "### frpc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6AO1HoRZ312",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget \"https://github.com/fatedier/frp/releases/download/v0.24.1/frp_0.24.1_linux_amd64.tar.gz\"\n",
        "!mkdir frp\n",
        "!tar -xvf \"frp_0.24.1_linux_amd64.tar.gz\" -C frp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUuPu_4XaF7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw(\"./frp/frp_0.24.1_linux_amd64/frpc -c ./frpc.ini &\")\n",
        "#!./frp/frp_0.24.1_linux_amd64/frpc -c ./frpc.ini"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkihmyBHaSew",
        "colab_type": "text"
      },
      "source": [
        "#======================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_J54DcdaiTv",
        "colab_type": "text"
      },
      "source": [
        "# Real things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aMS0VgEdVRO",
        "colab_type": "code",
        "outputId": "bac2f855-ffd9-418e-e063-c0024f9e8e50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "print(f'using pytorch {torch.version.__version__}')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using pytorch 1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN9yen-3ap_W",
        "colab_type": "text"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ixCPj3FaokO",
        "colab_type": "code",
        "outputId": "e2977267-4690-45ca-b3f5-6933583e71ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # mean, std\n",
        "  ]  \n",
        ")\n",
        "\n",
        "dset_train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "dset_test  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "loader_train = DataLoader(dset_train, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "loader_test = DataLoader(dset_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAQ05DWRaRNJ",
        "colab_type": "code",
        "outputId": "01c09b78-befa-42dc-a14e-0eb6e024d047",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pdb\n",
        "\n",
        "# visulize some of them\n",
        "trainld_iter = iter(loader_train)\n",
        "images, labels = trainld_iter.next()\n",
        "\n",
        "imgrid = torchvision.utils.make_grid(images[:4])\n",
        "imgrid = imgrid / 2.0 + 0.5\n",
        "imgrid_np = imgrid.numpy()\n",
        "# pdb.set_trace()\n",
        "\n",
        "plt.imshow(imgrid_np.transpose([1,2,0]))\n",
        "plt.show()\n",
        "\n",
        "print([classes[x.item()] for x in labels[:4] ])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w9WLwA3p341qAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "['frog', 'truck', 'truck', 'deer']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwKG2e09NMub",
        "colab_type": "text"
      },
      "source": [
        "## The network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqimJl8PfC0y",
        "colab_type": "code",
        "outputId": "038e9031-c464-4a15-857a-f23fb97cae6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "import pdb\n",
        "\n",
        "class MyNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "    self.bn1   = nn.BatchNorm2d(64)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "    \n",
        "    self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "    self.bn2   = nn.BatchNorm2d(128)\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "    \n",
        "    self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
        "    self.bn3   = nn.BatchNorm2d(256)\n",
        "    self.relu3 = nn.ReLU()\n",
        "    self.pool3 = nn.MaxPool2d(kernel_size=2)  # (N, C, 4, 4)\n",
        "    \n",
        "    self.fc1 = nn.Linear(4*4*256, 100)\n",
        "    self.fc2 = nn.Linear(100, 100)\n",
        "    self.fc3 = nn.Linear(100, 10)\n",
        "    \n",
        "    self._init_weights()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    '''\n",
        "    x: the image batch of (N, C, H, W)\n",
        "    '''\n",
        "    x = self.bn1(self.conv1(x))\n",
        "    x = self.pool1(self.relu1(x))\n",
        "\n",
        "    x = self.bn2(self.conv2(x))\n",
        "    x = self.pool2(self.relu2(x))\n",
        "    \n",
        "    x = self.bn3(self.conv3(x))\n",
        "    x = self.pool3(self.relu3(x))\n",
        "    \n",
        "    s = x.view((x.shape[0], -1))\n",
        "\n",
        "    s = self.fc1(s)\n",
        "    s = self.fc2(s)\n",
        "    s = self.fc3(s)\n",
        "    \n",
        "    return s\n",
        "    \n",
        "  def _init_weights(self):\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Linear):\n",
        "        nn.init.kaiming_normal_(m.weight.data, nonlinearity='relu')\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        nn.init.kaiming_normal_(m.weight.data, nonlinearity='relu')\n",
        "\n",
        "def test_net():\n",
        "  model = MyNet()\n",
        "  x = torch.randn(BATCH_SIZE, 3, 32, 32)\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    s = model(x)\n",
        "  print(s.size())\n",
        "  \n",
        "test_net()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VmtJOlbffkC",
        "colab_type": "text"
      },
      "source": [
        "## Training function(s)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RaiNqlpRq7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir runs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvCweiU5dZVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_checkpoint(model, optimizer, tfx_status_dict, ckpt_name='ckpt.pth'):\n",
        "  state = {\n",
        "      'model_state_dict': model.state_dict(),\n",
        "      'optimizer_state_dict': optimizer.state_dict(),\n",
        "      'tfx_status_dict': tfx_status_dict\n",
        "  }\n",
        "  torch.save(state, ckpt_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oS7_SP4SHJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import pdb\n",
        "\n",
        "def train(model, loader_train, optimizer, tfx_status_dict,\n",
        "          epochs=1, loss_fn=nn.CrossEntropyLoss(), dev=torch.device('cuda')):\n",
        "  writer = SummaryWriter(log_dir='./runs/original')  # note the difference between logdir and log_dir\n",
        "  for e in range(epochs):\n",
        "    print(f'epoch {tfx_status_dict[\"epochs\"]}')\n",
        "    for t, (images, labels) in enumerate(loader_train):\n",
        "      model.train()\n",
        "      images = images.to(device=dev)\n",
        "      labels = labels.to(device=dev)\n",
        "      optimizer.zero_grad()\n",
        "      scores = model(images)\n",
        "\n",
        "      loss = loss_fn(scores, labels)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      if t % 50 == 0:\n",
        "        print(f'iteration {t}/{len(loader_train)}, loss={loss.item()}')\n",
        "      tfx_status_dict['steps'] += 1\n",
        "      \n",
        "      writer.add_scalar('train/loss', loss.item(), tfx_status_dict['steps'])\n",
        "    \n",
        "    tfx_status_dict['epochs'] += 1\n",
        "    \n",
        "    writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjFC3u7TN3Py",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import pdb\n",
        "\n",
        "def train_with_l2_reg(model, loader_train, optimizer, tfx_status_dict, lambda_l2=1.0,\n",
        "          epochs=1, loss_fn=nn.CrossEntropyLoss(), dev=torch.device('cuda')):\n",
        "  writer = SummaryWriter(log_dir='./runs/with_l2_reg_2')  # note the difference between logdir and log_dir\n",
        "  for e in range(epochs):\n",
        "    print(f'epoch {tfx_status_dict[\"epochs\"]}')\n",
        "    for t, (images, labels) in enumerate(loader_train):\n",
        "      model.train()\n",
        "      images = images.to(device=dev)\n",
        "      labels = labels.to(device=dev)\n",
        "      optimizer.zero_grad()\n",
        "      scores = model(images)\n",
        "\n",
        "      loss_cross_entropy = loss_fn(scores, labels)\n",
        "      loss_l2 = 0.0\n",
        "      for p in model.parameters():\n",
        "        loss_l2 += p.norm()\n",
        "      \n",
        "      loss = loss_cross_entropy + lambda_l2 * loss_l2\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      if t % 50 == 0:\n",
        "        print(f'iteration {t}/{len(loader_train)}, loss={loss.item()}')\n",
        "      tfx_status_dict['steps'] += 1\n",
        "      \n",
        "      writer.add_scalars('train/loss', {\n",
        "          'loss_cross_entropy': loss_cross_entropy.item(),\n",
        "          'loss_l2'           : loss_l2.item(),\n",
        "          'loss'              : loss.item()\n",
        "      },\n",
        "               tfx_status_dict['steps'])\n",
        "    \n",
        "    tfx_status_dict['epochs'] += 1\n",
        "    \n",
        "    writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTiwqDy0cNXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import pdb\n",
        "\n",
        "def train_with_l1_reg(model, loader_train, optimizer, tfx_status_dict, lambda_l1=1.0,\n",
        "          epochs=1, loss_fn=nn.CrossEntropyLoss(), dev=torch.device('cuda')):\n",
        "  writer = SummaryWriter(log_dir='./runs/with_l1_reg_2')  # note the difference between logdir and log_dir\n",
        "  for e in range(epochs):\n",
        "    print(f'epoch {tfx_status_dict[\"epochs\"]}')\n",
        "    for t, (images, labels) in enumerate(loader_train):\n",
        "      model.train()\n",
        "      images = images.to(device=dev)\n",
        "      labels = labels.to(device=dev)\n",
        "      optimizer.zero_grad()\n",
        "      scores = model(images)\n",
        "\n",
        "      loss_cross_entropy = loss_fn(scores, labels)\n",
        "      loss_l1 = 0.0\n",
        "      for p in model.parameters():\n",
        "        loss_l1 += p.norm(p=1)\n",
        "      \n",
        "      loss = loss_cross_entropy + lambda_l1 * loss_l1\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      if t % 50 == 0:\n",
        "        print(f'iteration {t}/{len(loader_train)}, loss={loss.item()}')\n",
        "      tfx_status_dict['steps'] += 1\n",
        "      \n",
        "      writer.add_scalars('train/loss', {\n",
        "          'loss_cross_entropy': loss_cross_entropy.item(),\n",
        "          'loss_l1'           : loss_l1.item(),\n",
        "          'loss'              : loss.item()\n",
        "      },\n",
        "               tfx_status_dict['steps'])\n",
        "    \n",
        "    tfx_status_dict['epochs'] += 1\n",
        "    \n",
        "    writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms2OD69JZ9vG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4058d4e9-d823-4b4b-d130-15e027520dbc"
      },
      "source": [
        "try:\n",
        "  del model\n",
        "  print(\"deleted existing model\")\n",
        "except NameError:\n",
        "  pass\n",
        "\n",
        "model = MyNet()  \n",
        "model = model.cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "tfx_status_dict = {'steps':0, 'epochs':0}"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deleted existing model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuxLZu-dVknc",
        "colab_type": "text"
      },
      "source": [
        "## Inline tensorboard and training\n",
        "Need tensorflow >= 2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgHs24WlizhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir runs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWS8vfhafv51",
        "colab_type": "code",
        "outputId": "18e28e47-d49d-45e1-c22d-880110bceeb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train(model, loader_train, optimizer, tfx_status_dict, epochs=50)\n",
        "\n",
        "# train_with_l2_reg(model, loader_train, optimizer, tfx_status_dict, lambda_l2=0.005, epochs=10)\n",
        "# train_with_l2_reg(model, loader_train, optimizer, tfx_status_dict, lambda_l2=0.0005, epochs=10)\n",
        "# train_with_l2_reg(model, loader_train, optimizer, tfx_status_dict, lambda_l2=0.001, epochs=10)\n",
        "# train_with_l2_reg(model, loader_train, optimizer, tfx_status_dict, lambda_l2=0.001, epochs=20)\n",
        "\n",
        "# train_with_l1_reg(model, loader_train, optimizer, tfx_status_dict, lambda_l1=0.01, epochs=10)\n",
        "train_with_l1_reg(model, loader_train, optimizer, tfx_status_dict, lambda_l1=0.01, epochs=40)\n",
        "\n",
        "print(\"Done\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 10\n",
            "iteration 0/782, loss=2.8627471923828125\n",
            "iteration 50/782, loss=2.827289581298828\n",
            "iteration 100/782, loss=2.7558608055114746\n",
            "iteration 150/782, loss=2.8056254386901855\n",
            "iteration 200/782, loss=2.5629358291625977\n",
            "iteration 250/782, loss=2.705570697784424\n",
            "iteration 300/782, loss=2.7944743633270264\n",
            "iteration 350/782, loss=2.7039051055908203\n",
            "iteration 400/782, loss=2.763612747192383\n",
            "iteration 450/782, loss=2.4838833808898926\n",
            "iteration 500/782, loss=2.7851905822753906\n",
            "iteration 550/782, loss=2.6206140518188477\n",
            "iteration 600/782, loss=2.724606990814209\n",
            "iteration 650/782, loss=2.7772023677825928\n",
            "iteration 700/782, loss=2.814997911453247\n",
            "iteration 750/782, loss=3.147218704223633\n",
            "epoch 11\n",
            "iteration 0/782, loss=2.871213436126709\n",
            "iteration 50/782, loss=2.8326973915100098\n",
            "iteration 100/782, loss=2.7381343841552734\n",
            "iteration 150/782, loss=2.779848098754883\n",
            "iteration 200/782, loss=2.615354537963867\n",
            "iteration 250/782, loss=2.7115209102630615\n",
            "iteration 300/782, loss=2.789180278778076\n",
            "iteration 350/782, loss=2.6726131439208984\n",
            "iteration 400/782, loss=2.7713122367858887\n",
            "iteration 450/782, loss=2.476418972015381\n",
            "iteration 500/782, loss=2.7851364612579346\n",
            "iteration 550/782, loss=2.571824550628662\n",
            "iteration 600/782, loss=2.7190303802490234\n",
            "iteration 650/782, loss=2.7590560913085938\n",
            "iteration 700/782, loss=2.81998872756958\n",
            "iteration 750/782, loss=3.1025967597961426\n",
            "epoch 12\n",
            "iteration 0/782, loss=2.8346023559570312\n",
            "iteration 50/782, loss=2.8246841430664062\n",
            "iteration 100/782, loss=2.730329990386963\n",
            "iteration 150/782, loss=2.777738094329834\n",
            "iteration 200/782, loss=2.6130728721618652\n",
            "iteration 250/782, loss=2.6992290019989014\n",
            "iteration 300/782, loss=2.775789260864258\n",
            "iteration 350/782, loss=2.678070545196533\n",
            "iteration 400/782, loss=2.762971878051758\n",
            "iteration 450/782, loss=2.4861807823181152\n",
            "iteration 500/782, loss=2.7646195888519287\n",
            "iteration 550/782, loss=2.5172648429870605\n",
            "iteration 600/782, loss=2.7106165885925293\n",
            "iteration 650/782, loss=2.7481741905212402\n",
            "iteration 700/782, loss=2.8073949813842773\n",
            "iteration 750/782, loss=3.1523690223693848\n",
            "epoch 13\n",
            "iteration 0/782, loss=2.861271858215332\n",
            "iteration 50/782, loss=2.8265554904937744\n",
            "iteration 100/782, loss=2.728250026702881\n",
            "iteration 150/782, loss=2.7685728073120117\n",
            "iteration 200/782, loss=2.577622413635254\n",
            "iteration 250/782, loss=2.656498908996582\n",
            "iteration 300/782, loss=2.800713539123535\n",
            "iteration 350/782, loss=2.6914405822753906\n",
            "iteration 400/782, loss=2.7618446350097656\n",
            "iteration 450/782, loss=2.4985780715942383\n",
            "iteration 500/782, loss=2.7569665908813477\n",
            "iteration 550/782, loss=2.512021064758301\n",
            "iteration 600/782, loss=2.689730644226074\n",
            "iteration 650/782, loss=2.7480673789978027\n",
            "iteration 700/782, loss=2.805908679962158\n",
            "iteration 750/782, loss=3.106062173843384\n",
            "epoch 14\n",
            "iteration 0/782, loss=2.8037781715393066\n",
            "iteration 50/782, loss=2.825307846069336\n",
            "iteration 100/782, loss=2.7011733055114746\n",
            "iteration 150/782, loss=2.7355618476867676\n",
            "iteration 200/782, loss=2.5655386447906494\n",
            "iteration 250/782, loss=2.6552059650421143\n",
            "iteration 300/782, loss=2.780867576599121\n",
            "iteration 350/782, loss=2.71079683303833\n",
            "iteration 400/782, loss=2.8063201904296875\n",
            "iteration 450/782, loss=2.4890685081481934\n",
            "iteration 500/782, loss=2.754819393157959\n",
            "iteration 550/782, loss=2.4886207580566406\n",
            "iteration 600/782, loss=2.7499489784240723\n",
            "iteration 650/782, loss=2.7452354431152344\n",
            "iteration 700/782, loss=2.799900531768799\n",
            "iteration 750/782, loss=3.1307005882263184\n",
            "epoch 15\n",
            "iteration 0/782, loss=2.817267894744873\n",
            "iteration 50/782, loss=2.8867220878601074\n",
            "iteration 100/782, loss=2.688624858856201\n",
            "iteration 150/782, loss=2.776175022125244\n",
            "iteration 200/782, loss=2.597403049468994\n",
            "iteration 250/782, loss=2.651547908782959\n",
            "iteration 300/782, loss=2.768550157546997\n",
            "iteration 350/782, loss=2.745469093322754\n",
            "iteration 400/782, loss=2.7662930488586426\n",
            "iteration 450/782, loss=2.494537353515625\n",
            "iteration 500/782, loss=2.7561144828796387\n",
            "iteration 550/782, loss=2.4716079235076904\n",
            "iteration 600/782, loss=2.7269251346588135\n",
            "iteration 650/782, loss=2.7227044105529785\n",
            "iteration 700/782, loss=2.7863268852233887\n",
            "iteration 750/782, loss=3.1057214736938477\n",
            "epoch 16\n",
            "iteration 0/782, loss=2.829942464828491\n",
            "iteration 50/782, loss=2.8446707725524902\n",
            "iteration 100/782, loss=2.706071615219116\n",
            "iteration 150/782, loss=2.773965835571289\n",
            "iteration 200/782, loss=2.578429698944092\n",
            "iteration 250/782, loss=2.6423254013061523\n",
            "iteration 300/782, loss=2.791473865509033\n",
            "iteration 350/782, loss=2.729746103286743\n",
            "iteration 400/782, loss=2.775242805480957\n",
            "iteration 450/782, loss=2.4849166870117188\n",
            "iteration 500/782, loss=2.7479445934295654\n",
            "iteration 550/782, loss=2.4810032844543457\n",
            "iteration 600/782, loss=2.772118330001831\n",
            "iteration 650/782, loss=2.7053208351135254\n",
            "iteration 700/782, loss=2.7830846309661865\n",
            "iteration 750/782, loss=3.0641660690307617\n",
            "epoch 17\n",
            "iteration 0/782, loss=2.839656352996826\n",
            "iteration 50/782, loss=2.8717093467712402\n",
            "iteration 100/782, loss=2.694044828414917\n",
            "iteration 150/782, loss=2.7713098526000977\n",
            "iteration 200/782, loss=2.5897746086120605\n",
            "iteration 250/782, loss=2.6371021270751953\n",
            "iteration 300/782, loss=2.761435031890869\n",
            "iteration 350/782, loss=2.753554344177246\n",
            "iteration 400/782, loss=2.7714083194732666\n",
            "iteration 450/782, loss=2.4654910564422607\n",
            "iteration 500/782, loss=2.8113911151885986\n",
            "iteration 550/782, loss=2.4779319763183594\n",
            "iteration 600/782, loss=2.724292278289795\n",
            "iteration 650/782, loss=2.7022037506103516\n",
            "iteration 700/782, loss=2.75624418258667\n",
            "iteration 750/782, loss=3.124044179916382\n",
            "epoch 18\n",
            "iteration 0/782, loss=2.8408355712890625\n",
            "iteration 50/782, loss=2.8115220069885254\n",
            "iteration 100/782, loss=2.694767713546753\n",
            "iteration 150/782, loss=2.781129837036133\n",
            "iteration 200/782, loss=2.555372476577759\n",
            "iteration 250/782, loss=2.6165971755981445\n",
            "iteration 300/782, loss=2.7562100887298584\n",
            "iteration 350/782, loss=2.7271840572357178\n",
            "iteration 400/782, loss=2.771568775177002\n",
            "iteration 450/782, loss=2.471975803375244\n",
            "iteration 500/782, loss=2.7942144870758057\n",
            "iteration 550/782, loss=2.459895133972168\n",
            "iteration 600/782, loss=2.7022390365600586\n",
            "iteration 650/782, loss=2.7000484466552734\n",
            "iteration 700/782, loss=2.772963047027588\n",
            "iteration 750/782, loss=3.087024688720703\n",
            "epoch 19\n",
            "iteration 0/782, loss=2.831432819366455\n",
            "iteration 50/782, loss=2.7768354415893555\n",
            "iteration 100/782, loss=2.679241895675659\n",
            "iteration 150/782, loss=2.751138687133789\n",
            "iteration 200/782, loss=2.5636281967163086\n",
            "iteration 250/782, loss=2.6197924613952637\n",
            "iteration 300/782, loss=2.806502342224121\n",
            "iteration 350/782, loss=2.7342381477355957\n",
            "iteration 400/782, loss=2.788116931915283\n",
            "iteration 450/782, loss=2.4783220291137695\n",
            "iteration 500/782, loss=2.8066160678863525\n",
            "iteration 550/782, loss=2.4680516719818115\n",
            "iteration 600/782, loss=2.6722240447998047\n",
            "iteration 650/782, loss=2.707270622253418\n",
            "iteration 700/782, loss=2.742863655090332\n",
            "iteration 750/782, loss=3.0860581398010254\n",
            "epoch 20\n",
            "iteration 0/782, loss=2.785979747772217\n",
            "iteration 50/782, loss=2.7818493843078613\n",
            "iteration 100/782, loss=2.646552085876465\n",
            "iteration 150/782, loss=2.7522482872009277\n",
            "iteration 200/782, loss=2.488600730895996\n",
            "iteration 250/782, loss=2.646843671798706\n",
            "iteration 300/782, loss=2.7693610191345215\n",
            "iteration 350/782, loss=2.7066731452941895\n",
            "iteration 400/782, loss=2.74393367767334\n",
            "iteration 450/782, loss=2.4530258178710938\n",
            "iteration 500/782, loss=2.8116955757141113\n",
            "iteration 550/782, loss=2.456014633178711\n",
            "iteration 600/782, loss=2.6149168014526367\n",
            "iteration 650/782, loss=2.693305492401123\n",
            "iteration 700/782, loss=2.7293643951416016\n",
            "iteration 750/782, loss=3.0243959426879883\n",
            "epoch 21\n",
            "iteration 0/782, loss=2.899091958999634\n",
            "iteration 50/782, loss=2.7942423820495605\n",
            "iteration 100/782, loss=2.6771109104156494\n",
            "iteration 150/782, loss=2.7495946884155273\n",
            "iteration 200/782, loss=2.540933609008789\n",
            "iteration 250/782, loss=2.6027588844299316\n",
            "iteration 300/782, loss=2.7613699436187744\n",
            "iteration 350/782, loss=2.7014291286468506\n",
            "iteration 400/782, loss=2.7500250339508057\n",
            "iteration 450/782, loss=2.4705216884613037\n",
            "iteration 500/782, loss=2.7942967414855957\n",
            "iteration 550/782, loss=2.438636302947998\n",
            "iteration 600/782, loss=2.6361682415008545\n",
            "iteration 650/782, loss=2.665040969848633\n",
            "iteration 700/782, loss=2.7253150939941406\n",
            "iteration 750/782, loss=3.02756929397583\n",
            "epoch 22\n",
            "iteration 0/782, loss=2.88486385345459\n",
            "iteration 50/782, loss=2.764939785003662\n",
            "iteration 100/782, loss=2.656559467315674\n",
            "iteration 150/782, loss=2.7464187145233154\n",
            "iteration 200/782, loss=2.5170981884002686\n",
            "iteration 250/782, loss=2.6445722579956055\n",
            "iteration 300/782, loss=2.776639461517334\n",
            "iteration 350/782, loss=2.7134952545166016\n",
            "iteration 400/782, loss=2.7711665630340576\n",
            "iteration 450/782, loss=2.454699993133545\n",
            "iteration 500/782, loss=2.7977397441864014\n",
            "iteration 550/782, loss=2.4520130157470703\n",
            "iteration 600/782, loss=2.6124074459075928\n",
            "iteration 650/782, loss=2.641749858856201\n",
            "iteration 700/782, loss=2.7279610633850098\n",
            "iteration 750/782, loss=3.029384136199951\n",
            "epoch 23\n",
            "iteration 0/782, loss=2.8575899600982666\n",
            "iteration 50/782, loss=2.780851125717163\n",
            "iteration 100/782, loss=2.6317074298858643\n",
            "iteration 150/782, loss=2.7580349445343018\n",
            "iteration 200/782, loss=2.5353221893310547\n",
            "iteration 250/782, loss=2.649970293045044\n",
            "iteration 300/782, loss=2.738591194152832\n",
            "iteration 350/782, loss=2.6648824214935303\n",
            "iteration 400/782, loss=2.775409698486328\n",
            "iteration 450/782, loss=2.4531960487365723\n",
            "iteration 500/782, loss=2.8249382972717285\n",
            "iteration 550/782, loss=2.445094347000122\n",
            "iteration 600/782, loss=2.6114754676818848\n",
            "iteration 650/782, loss=2.63627552986145\n",
            "iteration 700/782, loss=2.729945421218872\n",
            "iteration 750/782, loss=2.9627020359039307\n",
            "epoch 24\n",
            "iteration 0/782, loss=2.8508994579315186\n",
            "iteration 50/782, loss=2.785505533218384\n",
            "iteration 100/782, loss=2.6582813262939453\n",
            "iteration 150/782, loss=2.7644100189208984\n",
            "iteration 200/782, loss=2.511417865753174\n",
            "iteration 250/782, loss=2.6310689449310303\n",
            "iteration 300/782, loss=2.7304558753967285\n",
            "iteration 350/782, loss=2.6683623790740967\n",
            "iteration 400/782, loss=2.7518045902252197\n",
            "iteration 450/782, loss=2.4601943492889404\n",
            "iteration 500/782, loss=2.8502840995788574\n",
            "iteration 550/782, loss=2.402662754058838\n",
            "iteration 600/782, loss=2.6191306114196777\n",
            "iteration 650/782, loss=2.647754669189453\n",
            "iteration 700/782, loss=2.7239294052124023\n",
            "iteration 750/782, loss=2.979462146759033\n",
            "epoch 25\n",
            "iteration 0/782, loss=2.8134217262268066\n",
            "iteration 50/782, loss=2.765164375305176\n",
            "iteration 100/782, loss=2.677797317504883\n",
            "iteration 150/782, loss=2.7510323524475098\n",
            "iteration 200/782, loss=2.5225257873535156\n",
            "iteration 250/782, loss=2.645460605621338\n",
            "iteration 300/782, loss=2.7418792247772217\n",
            "iteration 350/782, loss=2.6869354248046875\n",
            "iteration 400/782, loss=2.7457962036132812\n",
            "iteration 450/782, loss=2.4589438438415527\n",
            "iteration 500/782, loss=2.814948558807373\n",
            "iteration 550/782, loss=2.4361891746520996\n",
            "iteration 600/782, loss=2.6639373302459717\n",
            "iteration 650/782, loss=2.6337695121765137\n",
            "iteration 700/782, loss=2.717923641204834\n",
            "iteration 750/782, loss=2.9708127975463867\n",
            "epoch 26\n",
            "iteration 0/782, loss=2.811343193054199\n",
            "iteration 50/782, loss=2.782904624938965\n",
            "iteration 100/782, loss=2.6848573684692383\n",
            "iteration 150/782, loss=2.729534149169922\n",
            "iteration 200/782, loss=2.526111602783203\n",
            "iteration 250/782, loss=2.686765670776367\n",
            "iteration 300/782, loss=2.729093074798584\n",
            "iteration 350/782, loss=2.689955234527588\n",
            "iteration 400/782, loss=2.748716354370117\n",
            "iteration 450/782, loss=2.424346446990967\n",
            "iteration 500/782, loss=2.816000461578369\n",
            "iteration 550/782, loss=2.40956449508667\n",
            "iteration 600/782, loss=2.625093460083008\n",
            "iteration 650/782, loss=2.6452698707580566\n",
            "iteration 700/782, loss=2.7148869037628174\n",
            "iteration 750/782, loss=3.02120304107666\n",
            "epoch 27\n",
            "iteration 0/782, loss=2.838033676147461\n",
            "iteration 50/782, loss=2.778083562850952\n",
            "iteration 100/782, loss=2.680229902267456\n",
            "iteration 150/782, loss=2.763485908508301\n",
            "iteration 200/782, loss=2.5207881927490234\n",
            "iteration 250/782, loss=2.6103529930114746\n",
            "iteration 300/782, loss=2.726494550704956\n",
            "iteration 350/782, loss=2.698498249053955\n",
            "iteration 400/782, loss=2.732128620147705\n",
            "iteration 450/782, loss=2.451903820037842\n",
            "iteration 500/782, loss=2.8037683963775635\n",
            "iteration 550/782, loss=2.441679000854492\n",
            "iteration 600/782, loss=2.659264087677002\n",
            "iteration 650/782, loss=2.60907244682312\n",
            "iteration 700/782, loss=2.709080696105957\n",
            "iteration 750/782, loss=2.9866526126861572\n",
            "epoch 28\n",
            "iteration 0/782, loss=2.7853071689605713\n",
            "iteration 50/782, loss=2.772108316421509\n",
            "iteration 100/782, loss=2.6865315437316895\n",
            "iteration 150/782, loss=2.750621795654297\n",
            "iteration 200/782, loss=2.5034589767456055\n",
            "iteration 250/782, loss=2.6184940338134766\n",
            "iteration 300/782, loss=2.7461977005004883\n",
            "iteration 350/782, loss=2.653240203857422\n",
            "iteration 400/782, loss=2.7756948471069336\n",
            "iteration 450/782, loss=2.4275104999542236\n",
            "iteration 500/782, loss=2.808966875076294\n",
            "iteration 550/782, loss=2.4272782802581787\n",
            "iteration 600/782, loss=2.6423568725585938\n",
            "iteration 650/782, loss=2.6293084621429443\n",
            "iteration 700/782, loss=2.698591947555542\n",
            "iteration 750/782, loss=2.910869598388672\n",
            "epoch 29\n",
            "iteration 0/782, loss=2.7943406105041504\n",
            "iteration 50/782, loss=2.7951440811157227\n",
            "iteration 100/782, loss=2.6887011528015137\n",
            "iteration 150/782, loss=2.753757953643799\n",
            "iteration 200/782, loss=2.4751675128936768\n",
            "iteration 250/782, loss=2.6344664096832275\n",
            "iteration 300/782, loss=2.748873472213745\n",
            "iteration 350/782, loss=2.6940317153930664\n",
            "iteration 400/782, loss=2.7772274017333984\n",
            "iteration 450/782, loss=2.4296538829803467\n",
            "iteration 500/782, loss=2.8178958892822266\n",
            "iteration 550/782, loss=2.443258762359619\n",
            "iteration 600/782, loss=2.6321821212768555\n",
            "iteration 650/782, loss=2.62711763381958\n",
            "iteration 700/782, loss=2.6952593326568604\n",
            "iteration 750/782, loss=2.9929871559143066\n",
            "epoch 30\n",
            "iteration 0/782, loss=2.7869150638580322\n",
            "iteration 50/782, loss=2.7580695152282715\n",
            "iteration 100/782, loss=2.70819091796875\n",
            "iteration 150/782, loss=2.7248730659484863\n",
            "iteration 200/782, loss=2.545476198196411\n",
            "iteration 250/782, loss=2.5995469093322754\n",
            "iteration 300/782, loss=2.7653818130493164\n",
            "iteration 350/782, loss=2.707547664642334\n",
            "iteration 400/782, loss=2.7847378253936768\n",
            "iteration 450/782, loss=2.4336471557617188\n",
            "iteration 500/782, loss=2.8332901000976562\n",
            "iteration 550/782, loss=2.4634742736816406\n",
            "iteration 600/782, loss=2.6518983840942383\n",
            "iteration 650/782, loss=2.640249013900757\n",
            "iteration 700/782, loss=2.7029056549072266\n",
            "iteration 750/782, loss=3.000431537628174\n",
            "epoch 31\n",
            "iteration 0/782, loss=2.767432451248169\n",
            "iteration 50/782, loss=2.760282516479492\n",
            "iteration 100/782, loss=2.6581926345825195\n",
            "iteration 150/782, loss=2.7145333290100098\n",
            "iteration 200/782, loss=2.481337547302246\n",
            "iteration 250/782, loss=2.601487159729004\n",
            "iteration 300/782, loss=2.7300987243652344\n",
            "iteration 350/782, loss=2.6889381408691406\n",
            "iteration 400/782, loss=2.7586610317230225\n",
            "iteration 450/782, loss=2.443730354309082\n",
            "iteration 500/782, loss=2.8254785537719727\n",
            "iteration 550/782, loss=2.435708522796631\n",
            "iteration 600/782, loss=2.6130104064941406\n",
            "iteration 650/782, loss=2.6280157566070557\n",
            "iteration 700/782, loss=2.6860432624816895\n",
            "iteration 750/782, loss=2.9577879905700684\n",
            "epoch 32\n",
            "iteration 0/782, loss=2.7580690383911133\n",
            "iteration 50/782, loss=2.7631494998931885\n",
            "iteration 100/782, loss=2.691680908203125\n",
            "iteration 150/782, loss=2.729264974594116\n",
            "iteration 200/782, loss=2.5130343437194824\n",
            "iteration 250/782, loss=2.581700325012207\n",
            "iteration 300/782, loss=2.7316324710845947\n",
            "iteration 350/782, loss=2.682387351989746\n",
            "iteration 400/782, loss=2.7630958557128906\n",
            "iteration 450/782, loss=2.470186948776245\n",
            "iteration 500/782, loss=2.8501954078674316\n",
            "iteration 550/782, loss=2.4790101051330566\n",
            "iteration 600/782, loss=2.652210235595703\n",
            "iteration 650/782, loss=2.6139583587646484\n",
            "iteration 700/782, loss=2.6861886978149414\n",
            "iteration 750/782, loss=2.9561634063720703\n",
            "epoch 33\n",
            "iteration 0/782, loss=2.746875762939453\n",
            "iteration 50/782, loss=2.7683587074279785\n",
            "iteration 100/782, loss=2.7078518867492676\n",
            "iteration 150/782, loss=2.7169551849365234\n",
            "iteration 200/782, loss=2.4762930870056152\n",
            "iteration 250/782, loss=2.6101741790771484\n",
            "iteration 300/782, loss=2.7282333374023438\n",
            "iteration 350/782, loss=2.6882612705230713\n",
            "iteration 400/782, loss=2.72385311126709\n",
            "iteration 450/782, loss=2.4511847496032715\n",
            "iteration 500/782, loss=2.8316402435302734\n",
            "iteration 550/782, loss=2.423933982849121\n",
            "iteration 600/782, loss=2.633411407470703\n",
            "iteration 650/782, loss=2.6039929389953613\n",
            "iteration 700/782, loss=2.6621792316436768\n",
            "iteration 750/782, loss=3.0331950187683105\n",
            "epoch 34\n",
            "iteration 0/782, loss=2.7478389739990234\n",
            "iteration 50/782, loss=2.757127285003662\n",
            "iteration 100/782, loss=2.6688451766967773\n",
            "iteration 150/782, loss=2.738306999206543\n",
            "iteration 200/782, loss=2.5049829483032227\n",
            "iteration 250/782, loss=2.6006813049316406\n",
            "iteration 300/782, loss=2.730314016342163\n",
            "iteration 350/782, loss=2.6732845306396484\n",
            "iteration 400/782, loss=2.7321267127990723\n",
            "iteration 450/782, loss=2.453660488128662\n",
            "iteration 500/782, loss=2.7954463958740234\n",
            "iteration 550/782, loss=2.4096765518188477\n",
            "iteration 600/782, loss=2.6475071907043457\n",
            "iteration 650/782, loss=2.594965934753418\n",
            "iteration 700/782, loss=2.6286003589630127\n",
            "iteration 750/782, loss=2.984734058380127\n",
            "epoch 35\n",
            "iteration 0/782, loss=2.7474827766418457\n",
            "iteration 50/782, loss=2.797135829925537\n",
            "iteration 100/782, loss=2.6839723587036133\n",
            "iteration 150/782, loss=2.744321823120117\n",
            "iteration 200/782, loss=2.496127128601074\n",
            "iteration 250/782, loss=2.611060380935669\n",
            "iteration 300/782, loss=2.7313942909240723\n",
            "iteration 350/782, loss=2.6647801399230957\n",
            "iteration 400/782, loss=2.7553367614746094\n",
            "iteration 450/782, loss=2.4627747535705566\n",
            "iteration 500/782, loss=2.7931151390075684\n",
            "iteration 550/782, loss=2.427114963531494\n",
            "iteration 600/782, loss=2.6475930213928223\n",
            "iteration 650/782, loss=2.6269588470458984\n",
            "iteration 700/782, loss=2.641752243041992\n",
            "iteration 750/782, loss=2.9634768962860107\n",
            "epoch 36\n",
            "iteration 0/782, loss=2.7503767013549805\n",
            "iteration 50/782, loss=2.729705810546875\n",
            "iteration 100/782, loss=2.7226386070251465\n",
            "iteration 150/782, loss=2.7582807540893555\n",
            "iteration 200/782, loss=2.4892971515655518\n",
            "iteration 250/782, loss=2.610267162322998\n",
            "iteration 300/782, loss=2.745246410369873\n",
            "iteration 350/782, loss=2.6477460861206055\n",
            "iteration 400/782, loss=2.766345500946045\n",
            "iteration 450/782, loss=2.4463438987731934\n",
            "iteration 500/782, loss=2.802227735519409\n",
            "iteration 550/782, loss=2.4357621669769287\n",
            "iteration 600/782, loss=2.6535322666168213\n",
            "iteration 650/782, loss=2.6103734970092773\n",
            "iteration 700/782, loss=2.645867347717285\n",
            "iteration 750/782, loss=3.013446807861328\n",
            "epoch 37\n",
            "iteration 0/782, loss=2.7241148948669434\n",
            "iteration 50/782, loss=2.745281219482422\n",
            "iteration 100/782, loss=2.6995458602905273\n",
            "iteration 150/782, loss=2.7459492683410645\n",
            "iteration 200/782, loss=2.4630703926086426\n",
            "iteration 250/782, loss=2.6526026725769043\n",
            "iteration 300/782, loss=2.750239372253418\n",
            "iteration 350/782, loss=2.649371385574341\n",
            "iteration 400/782, loss=2.7676010131835938\n",
            "iteration 450/782, loss=2.4340524673461914\n",
            "iteration 500/782, loss=2.820127487182617\n",
            "iteration 550/782, loss=2.439167022705078\n",
            "iteration 600/782, loss=2.6591391563415527\n",
            "iteration 650/782, loss=2.588696241378784\n",
            "iteration 700/782, loss=2.649228811264038\n",
            "iteration 750/782, loss=2.9787845611572266\n",
            "epoch 38\n",
            "iteration 0/782, loss=2.739229679107666\n",
            "iteration 50/782, loss=2.729950428009033\n",
            "iteration 100/782, loss=2.7087714672088623\n",
            "iteration 150/782, loss=2.688838481903076\n",
            "iteration 200/782, loss=2.5106778144836426\n",
            "iteration 250/782, loss=2.6533327102661133\n",
            "iteration 300/782, loss=2.766892194747925\n",
            "iteration 350/782, loss=2.6595780849456787\n",
            "iteration 400/782, loss=2.7510008811950684\n",
            "iteration 450/782, loss=2.4545657634735107\n",
            "iteration 500/782, loss=2.829375982284546\n",
            "iteration 550/782, loss=2.445979118347168\n",
            "iteration 600/782, loss=2.649256467819214\n",
            "iteration 650/782, loss=2.6223766803741455\n",
            "iteration 700/782, loss=2.613313674926758\n",
            "iteration 750/782, loss=3.026517629623413\n",
            "epoch 39\n",
            "iteration 0/782, loss=2.724151134490967\n",
            "iteration 50/782, loss=2.7379021644592285\n",
            "iteration 100/782, loss=2.6955790519714355\n",
            "iteration 150/782, loss=2.7257730960845947\n",
            "iteration 200/782, loss=2.532447099685669\n",
            "iteration 250/782, loss=2.583552122116089\n",
            "iteration 300/782, loss=2.7540290355682373\n",
            "iteration 350/782, loss=2.6554384231567383\n",
            "iteration 400/782, loss=2.7445318698883057\n",
            "iteration 450/782, loss=2.468365430831909\n",
            "iteration 500/782, loss=2.809384822845459\n",
            "iteration 550/782, loss=2.453211784362793\n",
            "iteration 600/782, loss=2.6861867904663086\n",
            "iteration 650/782, loss=2.591733932495117\n",
            "iteration 700/782, loss=2.62030029296875\n",
            "iteration 750/782, loss=2.9850502014160156\n",
            "epoch 40\n",
            "iteration 0/782, loss=2.696469783782959\n",
            "iteration 50/782, loss=2.7683887481689453\n",
            "iteration 100/782, loss=2.714794635772705\n",
            "iteration 150/782, loss=2.720506191253662\n",
            "iteration 200/782, loss=2.487699508666992\n",
            "iteration 250/782, loss=2.6230664253234863\n",
            "iteration 300/782, loss=2.730227470397949\n",
            "iteration 350/782, loss=2.6650550365448\n",
            "iteration 400/782, loss=2.7843151092529297\n",
            "iteration 450/782, loss=2.4325172901153564\n",
            "iteration 500/782, loss=2.829535484313965\n",
            "iteration 550/782, loss=2.459444522857666\n",
            "iteration 600/782, loss=2.6643552780151367\n",
            "iteration 650/782, loss=2.5974795818328857\n",
            "iteration 700/782, loss=2.6228599548339844\n",
            "iteration 750/782, loss=3.0084726810455322\n",
            "epoch 41\n",
            "iteration 0/782, loss=2.7333076000213623\n",
            "iteration 50/782, loss=2.7395012378692627\n",
            "iteration 100/782, loss=2.7267494201660156\n",
            "iteration 150/782, loss=2.7334487438201904\n",
            "iteration 200/782, loss=2.4817895889282227\n",
            "iteration 250/782, loss=2.6332926750183105\n",
            "iteration 300/782, loss=2.776439666748047\n",
            "iteration 350/782, loss=2.6611368656158447\n",
            "iteration 400/782, loss=2.7636866569519043\n",
            "iteration 450/782, loss=2.428717851638794\n",
            "iteration 500/782, loss=2.8051390647888184\n",
            "iteration 550/782, loss=2.4550888538360596\n",
            "iteration 600/782, loss=2.629953145980835\n",
            "iteration 650/782, loss=2.5822534561157227\n",
            "iteration 700/782, loss=2.6201930046081543\n",
            "iteration 750/782, loss=2.9875664710998535\n",
            "epoch 42\n",
            "iteration 0/782, loss=2.712766170501709\n",
            "iteration 50/782, loss=2.758073329925537\n",
            "iteration 100/782, loss=2.7270708084106445\n",
            "iteration 150/782, loss=2.773005485534668\n",
            "iteration 200/782, loss=2.541520118713379\n",
            "iteration 250/782, loss=2.6047892570495605\n",
            "iteration 300/782, loss=2.76969575881958\n",
            "iteration 350/782, loss=2.7001805305480957\n",
            "iteration 400/782, loss=2.778184413909912\n",
            "iteration 450/782, loss=2.4608211517333984\n",
            "iteration 500/782, loss=2.8030753135681152\n",
            "iteration 550/782, loss=2.468639850616455\n",
            "iteration 600/782, loss=2.6150248050689697\n",
            "iteration 650/782, loss=2.574553966522217\n",
            "iteration 700/782, loss=2.6140079498291016\n",
            "iteration 750/782, loss=3.0286686420440674\n",
            "epoch 43\n",
            "iteration 0/782, loss=2.734003782272339\n",
            "iteration 50/782, loss=2.7363743782043457\n",
            "iteration 100/782, loss=2.7338829040527344\n",
            "iteration 150/782, loss=2.732728958129883\n",
            "iteration 200/782, loss=2.5608551502227783\n",
            "iteration 250/782, loss=2.5973548889160156\n",
            "iteration 300/782, loss=2.753180980682373\n",
            "iteration 350/782, loss=2.6509249210357666\n",
            "iteration 400/782, loss=2.771879196166992\n",
            "iteration 450/782, loss=2.4519777297973633\n",
            "iteration 500/782, loss=2.8228211402893066\n",
            "iteration 550/782, loss=2.4473214149475098\n",
            "iteration 600/782, loss=2.61845064163208\n",
            "iteration 650/782, loss=2.594935417175293\n",
            "iteration 700/782, loss=2.6644554138183594\n",
            "iteration 750/782, loss=2.9556314945220947\n",
            "epoch 44\n",
            "iteration 0/782, loss=2.713611125946045\n",
            "iteration 50/782, loss=2.760011911392212\n",
            "iteration 100/782, loss=2.743879556655884\n",
            "iteration 150/782, loss=2.7246601581573486\n",
            "iteration 200/782, loss=2.582190990447998\n",
            "iteration 250/782, loss=2.607454776763916\n",
            "iteration 300/782, loss=2.7607972621917725\n",
            "iteration 350/782, loss=2.6610684394836426\n",
            "iteration 400/782, loss=2.782639980316162\n",
            "iteration 450/782, loss=2.4222631454467773\n",
            "iteration 500/782, loss=2.84122371673584\n",
            "iteration 550/782, loss=2.448293685913086\n",
            "iteration 600/782, loss=2.6422348022460938\n",
            "iteration 650/782, loss=2.606686592102051\n",
            "iteration 700/782, loss=2.649106502532959\n",
            "iteration 750/782, loss=2.9577765464782715\n",
            "epoch 45\n",
            "iteration 0/782, loss=2.7304975986480713\n",
            "iteration 50/782, loss=2.7450671195983887\n",
            "iteration 100/782, loss=2.723134994506836\n",
            "iteration 150/782, loss=2.7329518795013428\n",
            "iteration 200/782, loss=2.5413565635681152\n",
            "iteration 250/782, loss=2.609550952911377\n",
            "iteration 300/782, loss=2.7728350162506104\n",
            "iteration 350/782, loss=2.647387981414795\n",
            "iteration 400/782, loss=2.7660088539123535\n",
            "iteration 450/782, loss=2.433046340942383\n",
            "iteration 500/782, loss=2.834484577178955\n",
            "iteration 550/782, loss=2.4677677154541016\n",
            "iteration 600/782, loss=2.6236073970794678\n",
            "iteration 650/782, loss=2.6148874759674072\n",
            "iteration 700/782, loss=2.6114182472229004\n",
            "iteration 750/782, loss=2.9679148197174072\n",
            "epoch 46\n",
            "iteration 0/782, loss=2.7186219692230225\n",
            "iteration 50/782, loss=2.730170726776123\n",
            "iteration 100/782, loss=2.7346720695495605\n",
            "iteration 150/782, loss=2.7179956436157227\n",
            "iteration 200/782, loss=2.544494867324829\n",
            "iteration 250/782, loss=2.6394200325012207\n",
            "iteration 300/782, loss=2.771480083465576\n",
            "iteration 350/782, loss=2.6629226207733154\n",
            "iteration 400/782, loss=2.7701337337493896\n",
            "iteration 450/782, loss=2.448237180709839\n",
            "iteration 500/782, loss=2.8541975021362305\n",
            "iteration 550/782, loss=2.4750609397888184\n",
            "iteration 600/782, loss=2.60367488861084\n",
            "iteration 650/782, loss=2.621171712875366\n",
            "iteration 700/782, loss=2.6379759311676025\n",
            "iteration 750/782, loss=2.958608388900757\n",
            "epoch 47\n",
            "iteration 0/782, loss=2.7194924354553223\n",
            "iteration 50/782, loss=2.7558865547180176\n",
            "iteration 100/782, loss=2.7499024868011475\n",
            "iteration 150/782, loss=2.7362070083618164\n",
            "iteration 200/782, loss=2.555431842803955\n",
            "iteration 250/782, loss=2.6350364685058594\n",
            "iteration 300/782, loss=2.7637248039245605\n",
            "iteration 350/782, loss=2.672822952270508\n",
            "iteration 400/782, loss=2.755341053009033\n",
            "iteration 450/782, loss=2.4584107398986816\n",
            "iteration 500/782, loss=2.8443007469177246\n",
            "iteration 550/782, loss=2.4598636627197266\n",
            "iteration 600/782, loss=2.6315879821777344\n",
            "iteration 650/782, loss=2.592161178588867\n",
            "iteration 700/782, loss=2.6314148902893066\n",
            "iteration 750/782, loss=2.9674503803253174\n",
            "epoch 48\n",
            "iteration 0/782, loss=2.7120115756988525\n",
            "iteration 50/782, loss=2.7381739616394043\n",
            "iteration 100/782, loss=2.732874870300293\n",
            "iteration 150/782, loss=2.745245933532715\n",
            "iteration 200/782, loss=2.5696768760681152\n",
            "iteration 250/782, loss=2.621333360671997\n",
            "iteration 300/782, loss=2.7643821239471436\n",
            "iteration 350/782, loss=2.6613407135009766\n",
            "iteration 400/782, loss=2.80509090423584\n",
            "iteration 450/782, loss=2.4131669998168945\n",
            "iteration 500/782, loss=2.848599433898926\n",
            "iteration 550/782, loss=2.4542393684387207\n",
            "iteration 600/782, loss=2.6455025672912598\n",
            "iteration 650/782, loss=2.611917018890381\n",
            "iteration 700/782, loss=2.627963066101074\n",
            "iteration 750/782, loss=2.959059715270996\n",
            "epoch 49\n",
            "iteration 0/782, loss=2.690840721130371\n",
            "iteration 50/782, loss=2.751673936843872\n",
            "iteration 100/782, loss=2.7160091400146484\n",
            "iteration 150/782, loss=2.741009473800659\n",
            "iteration 200/782, loss=2.548201560974121\n",
            "iteration 250/782, loss=2.6461777687072754\n",
            "iteration 300/782, loss=2.781456470489502\n",
            "iteration 350/782, loss=2.618147373199463\n",
            "iteration 400/782, loss=2.7576184272766113\n",
            "iteration 450/782, loss=2.4424071311950684\n",
            "iteration 500/782, loss=2.8440985679626465\n",
            "iteration 550/782, loss=2.465322494506836\n",
            "iteration 600/782, loss=2.6396777629852295\n",
            "iteration 650/782, loss=2.5696182250976562\n",
            "iteration 700/782, loss=2.644106388092041\n",
            "iteration 750/782, loss=2.9883275032043457\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KNxlRI6f8Yi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8d9c329d-f6df-4e02-fb16-0009277d130b"
      },
      "source": [
        "print(tfx_status_dict)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'steps': 39100, 'epochs': 50}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATqvBrzxeRyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_checkpoint(model, optimizer, tfx_status_dict, 'with_l1_reg.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrjTlOzcv_GU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eb59e373-c041-4908-c03c-e42f521f8621"
      },
      "source": [
        "!tar -cjvf runs.tar.bz2 runs"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "runs/\n",
            "runs/Jun25_06-10-04_58b9bfe23b37/\n",
            "runs/Jun25_06-10-04_58b9bfe23b37/events.out.tfevents.1561443004.58b9bfe23b37.3594.0\n",
            "runs/Jun25_06-10-23_58b9bfe23b37/\n",
            "runs/Jun25_06-10-23_58b9bfe23b37/events.out.tfevents.1561443023.58b9bfe23b37.3594.2\n",
            "runs/with_l2_reg_2/\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445267.58b9bfe23b37.117.335\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445127.58b9bfe23b37.117.299\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445318.58b9bfe23b37.117.351\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445102.58b9bfe23b37.117.291\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561444466.58b9bfe23b37.117.207\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445191.58b9bfe23b37.117.319\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445022.58b9bfe23b37.117.283\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445280.58b9bfe23b37.117.339\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445394.58b9bfe23b37.117.375\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445166.58b9bfe23b37.117.311\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445484.58b9bfe23b37.117.403\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561444491.58b9bfe23b37.117.215\n",
            "runs/with_l2_reg_2/train/\n",
            "runs/with_l2_reg_2/train/loss/\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561444983.58b9bfe23b37.117.273\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561444554.58b9bfe23b37.117.237\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445407.58b9bfe23b37.117.381\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561444479.58b9bfe23b37.117.213\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561444945.58b9bfe23b37.117.261\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561444529.58b9bfe23b37.117.229\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445318.58b9bfe23b37.117.353\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445166.58b9bfe23b37.117.313\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561444932.58b9bfe23b37.117.257\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445127.58b9bfe23b37.117.301\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445446.58b9bfe23b37.117.393\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561444958.58b9bfe23b37.117.265\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561444996.58b9bfe23b37.117.277\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561444970.58b9bfe23b37.117.269\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561444919.58b9bfe23b37.117.253\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561444491.58b9bfe23b37.117.217\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561444542.58b9bfe23b37.117.233\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445102.58b9bfe23b37.117.293\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445305.58b9bfe23b37.117.349\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445089.58b9bfe23b37.117.289\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561444517.58b9bfe23b37.117.225\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445204.58b9bfe23b37.117.325\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445369.58b9bfe23b37.117.369\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445458.58b9bfe23b37.117.397\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561444504.58b9bfe23b37.117.221\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445471.58b9bfe23b37.117.401\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445343.58b9bfe23b37.117.361\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445178.58b9bfe23b37.117.317\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445356.58b9bfe23b37.117.365\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561444906.58b9bfe23b37.117.249\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561444466.58b9bfe23b37.117.209\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561444579.58b9bfe23b37.117.245\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445241.58b9bfe23b37.117.329\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445293.58b9bfe23b37.117.345\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445420.58b9bfe23b37.117.385\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445394.58b9bfe23b37.117.377\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445433.58b9bfe23b37.117.389\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445009.58b9bfe23b37.117.281\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445331.58b9bfe23b37.117.357\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445191.58b9bfe23b37.117.321\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445254.58b9bfe23b37.117.333\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445267.58b9bfe23b37.117.337\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445115.58b9bfe23b37.117.297\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445280.58b9bfe23b37.117.341\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445022.58b9bfe23b37.117.285\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445382.58b9bfe23b37.117.373\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445140.58b9bfe23b37.117.305\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445484.58b9bfe23b37.117.405\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561445153.58b9bfe23b37.117.309\n",
            "runs/with_l2_reg_2/train/loss/loss_l2/events.out.tfevents.1561444567.58b9bfe23b37.117.241\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445446.58b9bfe23b37.117.392\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445433.58b9bfe23b37.117.388\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561444906.58b9bfe23b37.117.248\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445394.58b9bfe23b37.117.376\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445471.58b9bfe23b37.117.400\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445343.58b9bfe23b37.117.360\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445293.58b9bfe23b37.117.344\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561444529.58b9bfe23b37.117.228\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561444932.58b9bfe23b37.117.256\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445267.58b9bfe23b37.117.336\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445140.58b9bfe23b37.117.304\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445382.58b9bfe23b37.117.372\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561444517.58b9bfe23b37.117.224\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561444542.58b9bfe23b37.117.232\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445115.58b9bfe23b37.117.296\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445241.58b9bfe23b37.117.328\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561444579.58b9bfe23b37.117.244\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445356.58b9bfe23b37.117.364\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445166.58b9bfe23b37.117.312\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561444945.58b9bfe23b37.117.260\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445102.58b9bfe23b37.117.292\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561444567.58b9bfe23b37.117.240\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561444919.58b9bfe23b37.117.252\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561444466.58b9bfe23b37.117.208\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445305.58b9bfe23b37.117.348\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445254.58b9bfe23b37.117.332\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445153.58b9bfe23b37.117.308\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561444970.58b9bfe23b37.117.268\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445407.58b9bfe23b37.117.380\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445127.58b9bfe23b37.117.300\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445009.58b9bfe23b37.117.280\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561444958.58b9bfe23b37.117.264\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445191.58b9bfe23b37.117.320\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445178.58b9bfe23b37.117.316\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445331.58b9bfe23b37.117.356\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445458.58b9bfe23b37.117.396\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445420.58b9bfe23b37.117.384\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561444996.58b9bfe23b37.117.276\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561444504.58b9bfe23b37.117.220\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445280.58b9bfe23b37.117.340\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445318.58b9bfe23b37.117.352\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561444983.58b9bfe23b37.117.272\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561444554.58b9bfe23b37.117.236\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445089.58b9bfe23b37.117.288\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445204.58b9bfe23b37.117.324\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445484.58b9bfe23b37.117.404\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445369.58b9bfe23b37.117.368\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561444479.58b9bfe23b37.117.212\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561444491.58b9bfe23b37.117.216\n",
            "runs/with_l2_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561445022.58b9bfe23b37.117.284\n",
            "runs/with_l2_reg_2/train/loss/loss/\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561444983.58b9bfe23b37.117.274\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445009.58b9bfe23b37.117.282\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561444958.58b9bfe23b37.117.266\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561444919.58b9bfe23b37.117.254\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561444542.58b9bfe23b37.117.234\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561444906.58b9bfe23b37.117.250\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445280.58b9bfe23b37.117.342\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445115.58b9bfe23b37.117.298\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445382.58b9bfe23b37.117.374\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561444504.58b9bfe23b37.117.222\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445254.58b9bfe23b37.117.334\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445178.58b9bfe23b37.117.318\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445394.58b9bfe23b37.117.378\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445127.58b9bfe23b37.117.302\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445089.58b9bfe23b37.117.290\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445458.58b9bfe23b37.117.398\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561444579.58b9bfe23b37.117.246\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445293.58b9bfe23b37.117.346\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445446.58b9bfe23b37.117.394\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561444567.58b9bfe23b37.117.242\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561444970.58b9bfe23b37.117.270\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561444945.58b9bfe23b37.117.262\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445407.58b9bfe23b37.117.382\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445102.58b9bfe23b37.117.294\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445305.58b9bfe23b37.117.350\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561444517.58b9bfe23b37.117.226\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445153.58b9bfe23b37.117.310\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445318.58b9bfe23b37.117.354\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445241.58b9bfe23b37.117.330\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561444932.58b9bfe23b37.117.258\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445022.58b9bfe23b37.117.286\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445331.58b9bfe23b37.117.358\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445369.58b9bfe23b37.117.370\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561444996.58b9bfe23b37.117.278\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561444529.58b9bfe23b37.117.230\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561444466.58b9bfe23b37.117.210\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445471.58b9bfe23b37.117.402\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445420.58b9bfe23b37.117.386\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445343.58b9bfe23b37.117.362\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561444554.58b9bfe23b37.117.238\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445267.58b9bfe23b37.117.338\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445140.58b9bfe23b37.117.306\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445484.58b9bfe23b37.117.406\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445166.58b9bfe23b37.117.314\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445204.58b9bfe23b37.117.326\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561444479.58b9bfe23b37.117.214\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561444491.58b9bfe23b37.117.218\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445356.58b9bfe23b37.117.366\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445191.58b9bfe23b37.117.322\n",
            "runs/with_l2_reg_2/train/loss/loss/events.out.tfevents.1561445433.58b9bfe23b37.117.390\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445178.58b9bfe23b37.117.315\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445420.58b9bfe23b37.117.383\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445241.58b9bfe23b37.117.327\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561444517.58b9bfe23b37.117.223\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561444542.58b9bfe23b37.117.231\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445153.58b9bfe23b37.117.307\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561444996.58b9bfe23b37.117.275\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445305.58b9bfe23b37.117.347\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561444554.58b9bfe23b37.117.235\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445115.58b9bfe23b37.117.295\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445254.58b9bfe23b37.117.331\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445204.58b9bfe23b37.117.323\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445446.58b9bfe23b37.117.391\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561444529.58b9bfe23b37.117.227\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445458.58b9bfe23b37.117.395\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561444919.58b9bfe23b37.117.251\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561444958.58b9bfe23b37.117.263\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561444479.58b9bfe23b37.117.211\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561444983.58b9bfe23b37.117.271\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445407.58b9bfe23b37.117.379\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561444567.58b9bfe23b37.117.239\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445293.58b9bfe23b37.117.343\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561444970.58b9bfe23b37.117.267\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445140.58b9bfe23b37.117.303\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445331.58b9bfe23b37.117.355\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445382.58b9bfe23b37.117.371\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445356.58b9bfe23b37.117.363\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445343.58b9bfe23b37.117.359\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561444906.58b9bfe23b37.117.247\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445471.58b9bfe23b37.117.399\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445369.58b9bfe23b37.117.367\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445089.58b9bfe23b37.117.287\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561444504.58b9bfe23b37.117.219\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561444579.58b9bfe23b37.117.243\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561444945.58b9bfe23b37.117.259\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445009.58b9bfe23b37.117.279\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561444932.58b9bfe23b37.117.255\n",
            "runs/with_l2_reg_2/events.out.tfevents.1561445433.58b9bfe23b37.117.387\n",
            "runs/with_l1_reg_2/\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446756.58b9bfe23b37.117.551\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446618.58b9bfe23b37.117.507\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446718.58b9bfe23b37.117.539\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446744.58b9bfe23b37.117.547\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446920.58b9bfe23b37.117.603\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446460.58b9bfe23b37.117.463\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446447.58b9bfe23b37.117.459\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446643.58b9bfe23b37.117.515\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446705.58b9bfe23b37.117.535\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446782.58b9bfe23b37.117.559\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446832.58b9bfe23b37.117.575\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561447048.58b9bfe23b37.117.643\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446857.58b9bfe23b37.117.583\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446959.58b9bfe23b37.117.615\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446605.58b9bfe23b37.117.503\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446971.58b9bfe23b37.117.619\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446497.58b9bfe23b37.117.475\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561447035.58b9bfe23b37.117.639\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446819.58b9bfe23b37.117.571\n",
            "runs/with_l1_reg_2/train/\n",
            "runs/with_l1_reg_2/train/loss/\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446920.58b9bfe23b37.117.605\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446819.58b9bfe23b37.117.573\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561447035.58b9bfe23b37.117.641\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446971.58b9bfe23b37.117.621\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446895.58b9bfe23b37.117.597\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446959.58b9bfe23b37.117.617\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446592.58b9bfe23b37.117.501\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561447022.58b9bfe23b37.117.637\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446718.58b9bfe23b37.117.541\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446933.58b9bfe23b37.117.609\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446997.58b9bfe23b37.117.629\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446554.58b9bfe23b37.117.489\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446731.58b9bfe23b37.117.545\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446630.58b9bfe23b37.117.513\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446655.58b9bfe23b37.117.521\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446870.58b9bfe23b37.117.589\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446447.58b9bfe23b37.117.461\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446409.58b9bfe23b37.117.449\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446522.58b9bfe23b37.117.485\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446580.58b9bfe23b37.117.497\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446680.58b9bfe23b37.117.529\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446497.58b9bfe23b37.117.477\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446984.58b9bfe23b37.117.625\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446908.58b9bfe23b37.117.601\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446782.58b9bfe23b37.117.561\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446705.58b9bfe23b37.117.537\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446472.58b9bfe23b37.117.469\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446460.58b9bfe23b37.117.465\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446769.58b9bfe23b37.117.557\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446485.58b9bfe23b37.117.473\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446883.58b9bfe23b37.117.593\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446845.58b9bfe23b37.117.581\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446756.58b9bfe23b37.117.553\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446422.58b9bfe23b37.117.453\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446618.58b9bfe23b37.117.509\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446509.58b9bfe23b37.117.481\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561447009.58b9bfe23b37.117.633\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446794.58b9bfe23b37.117.565\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446435.58b9bfe23b37.117.457\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446693.58b9bfe23b37.117.533\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446643.58b9bfe23b37.117.517\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446605.58b9bfe23b37.117.505\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446567.58b9bfe23b37.117.493\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446744.58b9bfe23b37.117.549\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446857.58b9bfe23b37.117.585\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446807.58b9bfe23b37.117.569\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446668.58b9bfe23b37.117.525\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446946.58b9bfe23b37.117.613\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561446832.58b9bfe23b37.117.577\n",
            "runs/with_l1_reg_2/train/loss/loss_l1/events.out.tfevents.1561447048.58b9bfe23b37.117.645\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446782.58b9bfe23b37.117.560\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446908.58b9bfe23b37.117.600\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446497.58b9bfe23b37.117.476\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446435.58b9bfe23b37.117.456\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446409.58b9bfe23b37.117.448\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446946.58b9bfe23b37.117.612\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446580.58b9bfe23b37.117.496\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446655.58b9bfe23b37.117.520\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446618.58b9bfe23b37.117.508\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446630.58b9bfe23b37.117.512\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446997.58b9bfe23b37.117.628\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446819.58b9bfe23b37.117.572\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446769.58b9bfe23b37.117.556\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446845.58b9bfe23b37.117.580\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446984.58b9bfe23b37.117.624\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446832.58b9bfe23b37.117.576\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446756.58b9bfe23b37.117.552\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446554.58b9bfe23b37.117.488\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446605.58b9bfe23b37.117.504\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446509.58b9bfe23b37.117.480\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446883.58b9bfe23b37.117.592\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446731.58b9bfe23b37.117.544\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446807.58b9bfe23b37.117.568\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446592.58b9bfe23b37.117.500\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561447048.58b9bfe23b37.117.644\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446959.58b9bfe23b37.117.616\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446522.58b9bfe23b37.117.484\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446933.58b9bfe23b37.117.608\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446794.58b9bfe23b37.117.564\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446971.58b9bfe23b37.117.620\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446643.58b9bfe23b37.117.516\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446693.58b9bfe23b37.117.532\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446668.58b9bfe23b37.117.524\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446857.58b9bfe23b37.117.584\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446485.58b9bfe23b37.117.472\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446460.58b9bfe23b37.117.464\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446744.58b9bfe23b37.117.548\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446472.58b9bfe23b37.117.468\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446447.58b9bfe23b37.117.460\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446422.58b9bfe23b37.117.452\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446567.58b9bfe23b37.117.492\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446718.58b9bfe23b37.117.540\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446870.58b9bfe23b37.117.588\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561447022.58b9bfe23b37.117.636\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446680.58b9bfe23b37.117.528\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446895.58b9bfe23b37.117.596\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446705.58b9bfe23b37.117.536\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561447009.58b9bfe23b37.117.632\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561447035.58b9bfe23b37.117.640\n",
            "runs/with_l1_reg_2/train/loss/loss_cross_entropy/events.out.tfevents.1561446920.58b9bfe23b37.117.604\n",
            "runs/with_l1_reg_2/train/loss/loss/\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446567.58b9bfe23b37.117.494\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446819.58b9bfe23b37.117.574\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446870.58b9bfe23b37.117.590\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446435.58b9bfe23b37.117.458\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446718.58b9bfe23b37.117.542\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446422.58b9bfe23b37.117.454\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561447022.58b9bfe23b37.117.638\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446997.58b9bfe23b37.117.630\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446832.58b9bfe23b37.117.578\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446946.58b9bfe23b37.117.614\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446908.58b9bfe23b37.117.602\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446807.58b9bfe23b37.117.570\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446605.58b9bfe23b37.117.506\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446782.58b9bfe23b37.117.562\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446472.58b9bfe23b37.117.470\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446883.58b9bfe23b37.117.594\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446756.58b9bfe23b37.117.554\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446460.58b9bfe23b37.117.466\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446618.58b9bfe23b37.117.510\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446668.58b9bfe23b37.117.526\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446959.58b9bfe23b37.117.618\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446971.58b9bfe23b37.117.622\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446522.58b9bfe23b37.117.486\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446592.58b9bfe23b37.117.502\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446447.58b9bfe23b37.117.462\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446895.58b9bfe23b37.117.598\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446744.58b9bfe23b37.117.550\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446984.58b9bfe23b37.117.626\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561447035.58b9bfe23b37.117.642\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446655.58b9bfe23b37.117.522\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446920.58b9bfe23b37.117.606\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446680.58b9bfe23b37.117.530\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446643.58b9bfe23b37.117.518\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561447048.58b9bfe23b37.117.646\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446857.58b9bfe23b37.117.586\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446705.58b9bfe23b37.117.538\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446845.58b9bfe23b37.117.582\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446769.58b9bfe23b37.117.558\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446731.58b9bfe23b37.117.546\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446497.58b9bfe23b37.117.478\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446794.58b9bfe23b37.117.566\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446933.58b9bfe23b37.117.610\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446580.58b9bfe23b37.117.498\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446485.58b9bfe23b37.117.474\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446693.58b9bfe23b37.117.534\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561447009.58b9bfe23b37.117.634\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446409.58b9bfe23b37.117.450\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446554.58b9bfe23b37.117.490\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446509.58b9bfe23b37.117.482\n",
            "runs/with_l1_reg_2/train/loss/loss/events.out.tfevents.1561446630.58b9bfe23b37.117.514\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446693.58b9bfe23b37.117.531\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446984.58b9bfe23b37.117.623\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446807.58b9bfe23b37.117.567\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446592.58b9bfe23b37.117.499\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446946.58b9bfe23b37.117.611\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446435.58b9bfe23b37.117.455\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446554.58b9bfe23b37.117.487\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446509.58b9bfe23b37.117.479\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446883.58b9bfe23b37.117.591\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446997.58b9bfe23b37.117.627\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446870.58b9bfe23b37.117.587\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446895.58b9bfe23b37.117.595\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446933.58b9bfe23b37.117.607\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446422.58b9bfe23b37.117.451\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446485.58b9bfe23b37.117.471\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446580.58b9bfe23b37.117.495\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446769.58b9bfe23b37.117.555\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446668.58b9bfe23b37.117.523\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446409.58b9bfe23b37.117.447\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446680.58b9bfe23b37.117.527\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446472.58b9bfe23b37.117.467\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446630.58b9bfe23b37.117.511\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446908.58b9bfe23b37.117.599\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446567.58b9bfe23b37.117.491\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446655.58b9bfe23b37.117.519\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446731.58b9bfe23b37.117.543\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561447022.58b9bfe23b37.117.635\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561447009.58b9bfe23b37.117.631\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446522.58b9bfe23b37.117.483\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446845.58b9bfe23b37.117.579\n",
            "runs/with_l1_reg_2/events.out.tfevents.1561446794.58b9bfe23b37.117.563\n",
            "runs/original/\n",
            "runs/original/events.out.tfevents.1561434073.58b9bfe23b37.117.8\n",
            "runs/original/events.out.tfevents.1561434174.58b9bfe23b37.117.17\n",
            "runs/original/events.out.tfevents.1561434106.58b9bfe23b37.117.11\n",
            "runs/original/events.out.tfevents.1561434118.58b9bfe23b37.117.12\n",
            "runs/original/events.out.tfevents.1561434345.58b9bfe23b37.117.32\n",
            "runs/original/events.out.tfevents.1561434243.58b9bfe23b37.117.23\n",
            "runs/original/events.out.tfevents.1561434288.58b9bfe23b37.117.27\n",
            "runs/original/events.out.tfevents.1561434425.58b9bfe23b37.117.39\n",
            "runs/original/events.out.tfevents.1561434186.58b9bfe23b37.117.18\n",
            "runs/original/events.out.tfevents.1561434266.58b9bfe23b37.117.25\n",
            "runs/original/events.out.tfevents.1561434494.58b9bfe23b37.117.45\n",
            "runs/original/events.out.tfevents.1561434311.58b9bfe23b37.117.29\n",
            "runs/original/events.out.tfevents.1561434437.58b9bfe23b37.117.40\n",
            "runs/original/events.out.tfevents.1561434482.58b9bfe23b37.117.44\n",
            "runs/original/events.out.tfevents.1561434357.58b9bfe23b37.117.33\n",
            "runs/original/events.out.tfevents.1561434403.58b9bfe23b37.117.37\n",
            "runs/original/events.out.tfevents.1561434197.58b9bfe23b37.117.19\n",
            "runs/original/events.out.tfevents.1561434231.58b9bfe23b37.117.22\n",
            "runs/original/events.out.tfevents.1561434277.58b9bfe23b37.117.26\n",
            "runs/original/events.out.tfevents.1561434016.58b9bfe23b37.117.3\n",
            "runs/original/events.out.tfevents.1561434334.58b9bfe23b37.117.31\n",
            "runs/original/events.out.tfevents.1561434095.58b9bfe23b37.117.10\n",
            "runs/original/events.out.tfevents.1561434220.58b9bfe23b37.117.21\n",
            "runs/original/events.out.tfevents.1561434505.58b9bfe23b37.117.46\n",
            "runs/original/events.out.tfevents.1561434300.58b9bfe23b37.117.28\n",
            "runs/original/events.out.tfevents.1561434539.58b9bfe23b37.117.49\n",
            "runs/original/events.out.tfevents.1561434005.58b9bfe23b37.117.2\n",
            "runs/original/events.out.tfevents.1561434254.58b9bfe23b37.117.24\n",
            "runs/original/events.out.tfevents.1561434140.58b9bfe23b37.117.14\n",
            "runs/original/events.out.tfevents.1561434448.58b9bfe23b37.117.41\n",
            "runs/original/events.out.tfevents.1561433994.58b9bfe23b37.117.1\n",
            "runs/original/events.out.tfevents.1561434209.58b9bfe23b37.117.20\n",
            "runs/original/events.out.tfevents.1561434129.58b9bfe23b37.117.13\n",
            "runs/original/events.out.tfevents.1561434061.58b9bfe23b37.117.7\n",
            "runs/original/events.out.tfevents.1561434368.58b9bfe23b37.117.34\n",
            "runs/original/events.out.tfevents.1561434027.58b9bfe23b37.117.4\n",
            "runs/original/events.out.tfevents.1561433982.58b9bfe23b37.117.0\n",
            "runs/original/events.out.tfevents.1561434460.58b9bfe23b37.117.42\n",
            "runs/original/events.out.tfevents.1561434517.58b9bfe23b37.117.47\n",
            "runs/original/events.out.tfevents.1561434391.58b9bfe23b37.117.36\n",
            "runs/original/events.out.tfevents.1561434152.58b9bfe23b37.117.15\n",
            "runs/original/events.out.tfevents.1561434050.58b9bfe23b37.117.6\n",
            "runs/original/events.out.tfevents.1561434471.58b9bfe23b37.117.43\n",
            "runs/original/events.out.tfevents.1561434380.58b9bfe23b37.117.35\n",
            "runs/original/events.out.tfevents.1561434039.58b9bfe23b37.117.5\n",
            "runs/original/events.out.tfevents.1561434528.58b9bfe23b37.117.48\n",
            "runs/original/events.out.tfevents.1561434414.58b9bfe23b37.117.38\n",
            "runs/original/events.out.tfevents.1561434084.58b9bfe23b37.117.9\n",
            "runs/original/events.out.tfevents.1561434163.58b9bfe23b37.117.16\n",
            "runs/original/events.out.tfevents.1561434323.58b9bfe23b37.117.30\n",
            "runs/with_l1_reg_1/\n",
            "runs/with_l1_reg_1/events.out.tfevents.1561446273.58b9bfe23b37.117.415\n",
            "runs/with_l1_reg_1/events.out.tfevents.1561446285.58b9bfe23b37.117.419\n",
            "runs/with_l1_reg_1/events.out.tfevents.1561446359.58b9bfe23b37.117.443\n",
            "runs/with_l1_reg_1/events.out.tfevents.1561446297.58b9bfe23b37.117.423\n",
            "runs/with_l1_reg_1/events.out.tfevents.1561446322.58b9bfe23b37.117.431\n",
            "runs/with_l1_reg_1/train/\n",
            "runs/with_l1_reg_1/train/loss/\n",
            "runs/with_l1_reg_1/train/loss/loss_l1/\n",
            "runs/with_l1_reg_1/train/loss/loss_l1/events.out.tfevents.1561446359.58b9bfe23b37.117.445\n",
            "runs/with_l1_reg_1/train/loss/loss_l1/events.out.tfevents.1561446248.58b9bfe23b37.117.409\n",
            "runs/with_l1_reg_1/train/loss/loss_l1/events.out.tfevents.1561446334.58b9bfe23b37.117.437\n",
            "runs/with_l1_reg_1/train/loss/loss_l1/events.out.tfevents.1561446273.58b9bfe23b37.117.417\n",
            "runs/with_l1_reg_1/train/loss/loss_l1/events.out.tfevents.1561446310.58b9bfe23b37.117.429\n",
            "runs/with_l1_reg_1/train/loss/loss_l1/events.out.tfevents.1561446322.58b9bfe23b37.117.433\n",
            "runs/with_l1_reg_1/train/loss/loss_l1/events.out.tfevents.1561446260.58b9bfe23b37.117.413\n",
            "runs/with_l1_reg_1/train/loss/loss_l1/events.out.tfevents.1561446347.58b9bfe23b37.117.441\n",
            "runs/with_l1_reg_1/train/loss/loss_l1/events.out.tfevents.1561446297.58b9bfe23b37.117.425\n",
            "runs/with_l1_reg_1/train/loss/loss_l1/events.out.tfevents.1561446285.58b9bfe23b37.117.421\n",
            "runs/with_l1_reg_1/train/loss/loss_cross_entropy/\n",
            "runs/with_l1_reg_1/train/loss/loss_cross_entropy/events.out.tfevents.1561446347.58b9bfe23b37.117.440\n",
            "runs/with_l1_reg_1/train/loss/loss_cross_entropy/events.out.tfevents.1561446297.58b9bfe23b37.117.424\n",
            "runs/with_l1_reg_1/train/loss/loss_cross_entropy/events.out.tfevents.1561446322.58b9bfe23b37.117.432\n",
            "runs/with_l1_reg_1/train/loss/loss_cross_entropy/events.out.tfevents.1561446260.58b9bfe23b37.117.412\n",
            "runs/with_l1_reg_1/train/loss/loss_cross_entropy/events.out.tfevents.1561446359.58b9bfe23b37.117.444\n",
            "runs/with_l1_reg_1/train/loss/loss_cross_entropy/events.out.tfevents.1561446310.58b9bfe23b37.117.428\n",
            "runs/with_l1_reg_1/train/loss/loss_cross_entropy/events.out.tfevents.1561446248.58b9bfe23b37.117.408\n",
            "runs/with_l1_reg_1/train/loss/loss_cross_entropy/events.out.tfevents.1561446285.58b9bfe23b37.117.420\n",
            "runs/with_l1_reg_1/train/loss/loss_cross_entropy/events.out.tfevents.1561446273.58b9bfe23b37.117.416\n",
            "runs/with_l1_reg_1/train/loss/loss_cross_entropy/events.out.tfevents.1561446334.58b9bfe23b37.117.436\n",
            "runs/with_l1_reg_1/train/loss/loss/\n",
            "runs/with_l1_reg_1/train/loss/loss/events.out.tfevents.1561446334.58b9bfe23b37.117.438\n",
            "runs/with_l1_reg_1/train/loss/loss/events.out.tfevents.1561446310.58b9bfe23b37.117.430\n",
            "runs/with_l1_reg_1/train/loss/loss/events.out.tfevents.1561446260.58b9bfe23b37.117.414\n",
            "runs/with_l1_reg_1/train/loss/loss/events.out.tfevents.1561446347.58b9bfe23b37.117.442\n",
            "runs/with_l1_reg_1/train/loss/loss/events.out.tfevents.1561446297.58b9bfe23b37.117.426\n",
            "runs/with_l1_reg_1/train/loss/loss/events.out.tfevents.1561446248.58b9bfe23b37.117.410\n",
            "runs/with_l1_reg_1/train/loss/loss/events.out.tfevents.1561446322.58b9bfe23b37.117.434\n",
            "runs/with_l1_reg_1/train/loss/loss/events.out.tfevents.1561446285.58b9bfe23b37.117.422\n",
            "runs/with_l1_reg_1/train/loss/loss/events.out.tfevents.1561446359.58b9bfe23b37.117.446\n",
            "runs/with_l1_reg_1/train/loss/loss/events.out.tfevents.1561446273.58b9bfe23b37.117.418\n",
            "runs/with_l1_reg_1/events.out.tfevents.1561446260.58b9bfe23b37.117.411\n",
            "runs/with_l1_reg_1/events.out.tfevents.1561446247.58b9bfe23b37.117.407\n",
            "runs/with_l1_reg_1/events.out.tfevents.1561446334.58b9bfe23b37.117.435\n",
            "runs/with_l1_reg_1/events.out.tfevents.1561446347.58b9bfe23b37.117.439\n",
            "runs/with_l1_reg_1/events.out.tfevents.1561446310.58b9bfe23b37.117.427\n",
            "runs/Jun25_06-10-49_58b9bfe23b37/\n",
            "runs/Jun25_06-10-49_58b9bfe23b37/events.out.tfevents.1561443049.58b9bfe23b37.3594.4\n",
            "runs/with_l2_reg/\n",
            "runs/with_l2_reg/events.out.tfevents.1561444187.58b9bfe23b37.117.131\n",
            "runs/with_l2_reg/events.out.tfevents.1561443761.58b9bfe23b37.117.55\n",
            "runs/with_l2_reg/events.out.tfevents.1561444303.58b9bfe23b37.117.167\n",
            "runs/with_l2_reg/events.out.tfevents.1561444059.58b9bfe23b37.117.91\n",
            "runs/with_l2_reg/events.out.tfevents.1561443851.58b9bfe23b37.117.83\n",
            "runs/with_l2_reg/events.out.tfevents.1561444406.58b9bfe23b37.117.199\n",
            "runs/with_l2_reg/events.out.tfevents.1561444162.58b9bfe23b37.117.123\n",
            "runs/with_l2_reg/events.out.tfevents.1561444355.58b9bfe23b37.117.183\n",
            "runs/with_l2_reg/events.out.tfevents.1561444085.58b9bfe23b37.117.99\n",
            "runs/with_l2_reg/events.out.tfevents.1561443839.58b9bfe23b37.117.79\n",
            "runs/with_l2_reg/events.out.tfevents.1561444149.58b9bfe23b37.117.119\n",
            "runs/with_l2_reg/events.out.tfevents.1561444200.58b9bfe23b37.117.135\n",
            "runs/with_l2_reg/events.out.tfevents.1561443813.58b9bfe23b37.117.71\n",
            "runs/with_l2_reg/events.out.tfevents.1561444252.58b9bfe23b37.117.151\n",
            "runs/with_l2_reg/events.out.tfevents.1561444419.58b9bfe23b37.117.203\n",
            "runs/with_l2_reg/events.out.tfevents.1561444175.58b9bfe23b37.117.127\n",
            "runs/with_l2_reg/events.out.tfevents.1561444381.58b9bfe23b37.117.191\n",
            "runs/with_l2_reg/train/\n",
            "runs/with_l2_reg/train/loss/\n",
            "runs/with_l2_reg/train/loss/loss_l2/\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444406.58b9bfe23b37.117.201\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444136.58b9bfe23b37.117.117\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561443774.58b9bfe23b37.117.61\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444187.58b9bfe23b37.117.133\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444368.58b9bfe23b37.117.189\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444393.58b9bfe23b37.117.197\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444419.58b9bfe23b37.117.205\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444239.58b9bfe23b37.117.149\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561443839.58b9bfe23b37.117.81\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444111.58b9bfe23b37.117.109\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444059.58b9bfe23b37.117.93\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444252.58b9bfe23b37.117.153\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561443787.58b9bfe23b37.117.65\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444342.58b9bfe23b37.117.181\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444175.58b9bfe23b37.117.129\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444265.58b9bfe23b37.117.157\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561443813.58b9bfe23b37.117.73\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444124.58b9bfe23b37.117.113\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444226.58b9bfe23b37.117.145\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444072.58b9bfe23b37.117.97\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444316.58b9bfe23b37.117.173\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444278.58b9bfe23b37.117.161\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444355.58b9bfe23b37.117.185\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444085.58b9bfe23b37.117.101\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561443761.58b9bfe23b37.117.57\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561443851.58b9bfe23b37.117.85\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561443747.58b9bfe23b37.117.53\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444303.58b9bfe23b37.117.169\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561443826.58b9bfe23b37.117.77\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444381.58b9bfe23b37.117.193\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444291.58b9bfe23b37.117.165\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444329.58b9bfe23b37.117.177\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444149.58b9bfe23b37.117.121\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444162.58b9bfe23b37.117.125\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444200.58b9bfe23b37.117.137\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444213.58b9bfe23b37.117.141\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561444098.58b9bfe23b37.117.105\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561443800.58b9bfe23b37.117.69\n",
            "runs/with_l2_reg/train/loss/loss_l2/events.out.tfevents.1561443864.58b9bfe23b37.117.89\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444162.58b9bfe23b37.117.124\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444419.58b9bfe23b37.117.204\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444072.58b9bfe23b37.117.96\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444252.58b9bfe23b37.117.152\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444265.58b9bfe23b37.117.156\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444200.58b9bfe23b37.117.136\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444303.58b9bfe23b37.117.168\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444111.58b9bfe23b37.117.108\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444213.58b9bfe23b37.117.140\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561443813.58b9bfe23b37.117.72\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444329.58b9bfe23b37.117.176\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561443787.58b9bfe23b37.117.64\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561443864.58b9bfe23b37.117.88\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561443826.58b9bfe23b37.117.76\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561443851.58b9bfe23b37.117.84\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444278.58b9bfe23b37.117.160\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444381.58b9bfe23b37.117.192\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561443839.58b9bfe23b37.117.80\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561443761.58b9bfe23b37.117.56\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444226.58b9bfe23b37.117.144\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444342.58b9bfe23b37.117.180\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444124.58b9bfe23b37.117.112\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444316.58b9bfe23b37.117.172\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561443747.58b9bfe23b37.117.52\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444355.58b9bfe23b37.117.184\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444393.58b9bfe23b37.117.196\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444187.58b9bfe23b37.117.132\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444085.58b9bfe23b37.117.100\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444175.58b9bfe23b37.117.128\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444098.58b9bfe23b37.117.104\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561443800.58b9bfe23b37.117.68\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444136.58b9bfe23b37.117.116\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444291.58b9bfe23b37.117.164\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444239.58b9bfe23b37.117.148\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444149.58b9bfe23b37.117.120\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561443774.58b9bfe23b37.117.60\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444406.58b9bfe23b37.117.200\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444059.58b9bfe23b37.117.92\n",
            "runs/with_l2_reg/train/loss/loss_cross_entropy/events.out.tfevents.1561444368.58b9bfe23b37.117.188\n",
            "runs/with_l2_reg/train/loss/loss/\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444200.58b9bfe23b37.117.138\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444162.58b9bfe23b37.117.126\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444303.58b9bfe23b37.117.170\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444393.58b9bfe23b37.117.198\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561443813.58b9bfe23b37.117.74\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444136.58b9bfe23b37.117.118\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444187.58b9bfe23b37.117.134\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444316.58b9bfe23b37.117.174\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444072.58b9bfe23b37.117.98\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561443851.58b9bfe23b37.117.86\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444252.58b9bfe23b37.117.154\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444265.58b9bfe23b37.117.158\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444059.58b9bfe23b37.117.94\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444149.58b9bfe23b37.117.122\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444368.58b9bfe23b37.117.190\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561443826.58b9bfe23b37.117.78\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444124.58b9bfe23b37.117.114\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444342.58b9bfe23b37.117.182\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444291.58b9bfe23b37.117.166\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561443864.58b9bfe23b37.117.90\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444213.58b9bfe23b37.117.142\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444098.58b9bfe23b37.117.106\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561443761.58b9bfe23b37.117.58\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444175.58b9bfe23b37.117.130\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444085.58b9bfe23b37.117.102\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444239.58b9bfe23b37.117.150\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444355.58b9bfe23b37.117.186\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444329.58b9bfe23b37.117.178\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444226.58b9bfe23b37.117.146\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444381.58b9bfe23b37.117.194\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444111.58b9bfe23b37.117.110\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561443747.58b9bfe23b37.117.54\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561443839.58b9bfe23b37.117.82\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444419.58b9bfe23b37.117.206\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444406.58b9bfe23b37.117.202\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561443800.58b9bfe23b37.117.70\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561443774.58b9bfe23b37.117.62\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561444278.58b9bfe23b37.117.162\n",
            "runs/with_l2_reg/train/loss/loss/events.out.tfevents.1561443787.58b9bfe23b37.117.66\n",
            "runs/with_l2_reg/events.out.tfevents.1561444098.58b9bfe23b37.117.103\n",
            "runs/with_l2_reg/events.out.tfevents.1561444226.58b9bfe23b37.117.143\n",
            "runs/with_l2_reg/events.out.tfevents.1561444278.58b9bfe23b37.117.159\n",
            "runs/with_l2_reg/events.out.tfevents.1561444342.58b9bfe23b37.117.179\n",
            "runs/with_l2_reg/events.out.tfevents.1561444123.58b9bfe23b37.117.111\n",
            "runs/with_l2_reg/events.out.tfevents.1561444393.58b9bfe23b37.117.195\n",
            "runs/with_l2_reg/events.out.tfevents.1561443774.58b9bfe23b37.117.59\n",
            "runs/with_l2_reg/events.out.tfevents.1561443800.58b9bfe23b37.117.67\n",
            "runs/with_l2_reg/events.out.tfevents.1561444291.58b9bfe23b37.117.163\n",
            "runs/with_l2_reg/events.out.tfevents.1561444316.58b9bfe23b37.117.171\n",
            "runs/with_l2_reg/events.out.tfevents.1561444329.58b9bfe23b37.117.175\n",
            "runs/with_l2_reg/events.out.tfevents.1561443826.58b9bfe23b37.117.75\n",
            "runs/with_l2_reg/events.out.tfevents.1561443726.58b9bfe23b37.117.50\n",
            "runs/with_l2_reg/events.out.tfevents.1561444136.58b9bfe23b37.117.115\n",
            "runs/with_l2_reg/events.out.tfevents.1561444111.58b9bfe23b37.117.107\n",
            "runs/with_l2_reg/events.out.tfevents.1561444072.58b9bfe23b37.117.95\n",
            "runs/with_l2_reg/events.out.tfevents.1561444239.58b9bfe23b37.117.147\n",
            "runs/with_l2_reg/events.out.tfevents.1561443864.58b9bfe23b37.117.87\n",
            "runs/with_l2_reg/events.out.tfevents.1561444265.58b9bfe23b37.117.155\n",
            "runs/with_l2_reg/events.out.tfevents.1561443747.58b9bfe23b37.117.51\n",
            "runs/with_l2_reg/events.out.tfevents.1561443787.58b9bfe23b37.117.63\n",
            "runs/with_l2_reg/events.out.tfevents.1561444368.58b9bfe23b37.117.187\n",
            "runs/with_l2_reg/events.out.tfevents.1561444213.58b9bfe23b37.117.139\n",
            "runs/Jun25_06-10-59_58b9bfe23b37/\n",
            "runs/Jun25_06-10-59_58b9bfe23b37/events.out.tfevents.1561443059.58b9bfe23b37.3594.5\n",
            "runs/Jun25_06-10-17_58b9bfe23b37/\n",
            "runs/Jun25_06-10-17_58b9bfe23b37/events.out.tfevents.1561443017.58b9bfe23b37.3594.1\n",
            "runs/Jun25_06-10-43_58b9bfe23b37/\n",
            "runs/Jun25_06-10-43_58b9bfe23b37/events.out.tfevents.1561443043.58b9bfe23b37.3594.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3Ne-_jfespv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "98b5adbc-a79b-4c77-d51f-952c605e8377"
      },
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNCgCqKbfLFJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "1e030984-9ca5-47ea-8686-683870ccc4d6"
      },
      "source": [
        "!cp -v original.pth with_l1_reg.pth with_l2_reg.pth runs.tar.bz2 \"drive/My Drive/cifar10-playground\""
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'original.pth' -> 'drive/My Drive/cifar10-playground/original.pth'\n",
            "'with_l1_reg.pth' -> 'drive/My Drive/cifar10-playground/with_l1_reg.pth'\n",
            "'with_l2_reg.pth' -> 'drive/My Drive/cifar10-playground/with_l2_reg.pth'\n",
            "'runs.tar.bz2' -> 'drive/My Drive/cifar10-playground/runs.tar.bz2'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHcNH_OzZvBr",
        "colab_type": "text"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c_TfYV7ZuIB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "66a69052-f021-4100-c7a3-7ff0bd1192bd"
      },
      "source": [
        "import pdb\n",
        "\n",
        "def naive_acc(model):\n",
        "  classes_total = [0.0 for i in range(10)]\n",
        "  classes_correct = [0.0 for i in range(10)]\n",
        "  model.eval()\n",
        "  model = model.cuda()\n",
        "  with torch.no_grad():\n",
        "    for t, (images, labels) in enumerate(loader_test):\n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "      scores = model(images)\n",
        "      _, predicts = torch.max(scores, 1)\n",
        "      c = (predicts == labels)\n",
        "      for i, label in enumerate(labels):\n",
        "        classes_correct[label] += c[i].item()\n",
        "        classes_total[label] += 1\n",
        "  for i in range(10):\n",
        "    print(f'accuracy for class {i} is {classes_correct[i]/classes_total[i]}')\n",
        "  \n",
        "naive_acc(model)    "
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy for class 0 is 0.474\n",
            "accuracy for class 1 is 0.683\n",
            "accuracy for class 2 is 0.275\n",
            "accuracy for class 3 is 0.137\n",
            "accuracy for class 4 is 0.264\n",
            "accuracy for class 5 is 0.569\n",
            "accuracy for class 6 is 0.749\n",
            "accuracy for class 7 is 0.533\n",
            "accuracy for class 8 is 0.711\n",
            "accuracy for class 9 is 0.615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeDzJk78mOqo",
        "colab_type": "text"
      },
      "source": [
        "I am logging the experiments results.\n",
        "\n",
        "Using epochs=50, lr=1e-3\n",
        "\n",
        "class id | original | with l2 reg | with l1 reg |\n",
        "-------- | -------- | ----------- | ----------- |\n",
        "0        | 0.697    | 0.775       | 0.474\n",
        "1        | 0.875    | 0.872       | 0.683\n",
        "2        | 0.717    | 0.641       | 0.275\n",
        "3        | 0.604    | 0.663       | 0.137\n",
        "4        | 0.787    | 0.785       | 0.264\n",
        "5        | 0.684    | 0.722       | 0.569\n",
        "6        | 0.838    | 0.778       | 0.749\n",
        "7        | 0.776    | 0.844       | 0.533\n",
        "8        | 0.919    | 0.854       | 0.711\n",
        "9        | 0.886    | 0.802       | 0.615\n",
        "avg    | 0.778   | 0.777      | 0.501\n",
        "std     |0.102   | 0.078 | 0.210"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txfyH9aaht2L",
        "colab_type": "text"
      },
      "source": [
        "The experiment with L1 regularization seems to be poorly tuned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WExIrupepH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}